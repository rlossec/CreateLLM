{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e91126d3-9cb2-4c83-a73e-291c58ea95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0d121f-8adc-431b-af79-84a22a4e896b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716c56f3-a497-48ed-b9e8-0a4ee741068b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304ad76d-17c6-4098-97cb-358a113b631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5b183d-50e7-4dc9-9b4a-b1fd9b4603a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/wizard_of_oz.txt\", 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750b18b-bd22-4ce6-9412-6e7c89767d76",
   "metadata": {},
   "source": [
    "## Avec un Tokenizer par lettre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e1901c8-90e4-467a-a5b9-b0a29fab0c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste des caractères présents :\n",
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff'] \n",
      "\n",
      "Nombre de caractères présents :\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(\"Liste des caractères présents :\")\n",
    "print(chars, '\\n')\n",
    "vocab_size = len(chars)\n",
    "print(\"Nombre de caractères présents :\")\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563929b6-cb38-4bae-9479-1e1842cbf1b5",
   "metadata": {},
   "source": [
    "Construction de l'encodage du tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c245a794-2f2c-41a5-861c-16a59b8ab806",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "encode = lambda string: [string_to_int[char] for char in string]\n",
    "decode = lambda code  : ''.join([int_to_string[i] for i in code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a67dc3-aeda-42b5-aa7b-aac90e9c7fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hello' encodé : \n",
      " [61, 58, 65, 65, 68]\n",
      "\n",
      "Puis décodé: \n",
      " hello\n"
     ]
    }
   ],
   "source": [
    "## Tests\n",
    "\n",
    "encoded_hello = encode('hello')\n",
    "print(\"'hello' encodé : \\n\", encoded_hello)\n",
    "decoded_hello = decode(encoded_hello)\n",
    "print(\"\\nPuis décodé: \\n\", decoded_hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652d622-9108-4ff7-bb30-0719d08f6936",
   "metadata": {},
   "source": [
    "### Avec PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "105ef9f1-34cd-4c7c-9039-406e3e837b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14ec7b9-91bd-49aa-94f3-eda2930751db",
   "metadata": {},
   "source": [
    "100 premiers caractères encodés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a96f454c-b7e4-4b3c-97cb-361deb1a6d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
      "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26,\n",
      "        49,  0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,\n",
      "         0,  0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1,\n",
      "        47, 33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1,\n",
      "        36, 25, 38, 28,  1, 39, 30,  1, 39, 50])\n"
     ]
    }
   ],
   "source": [
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc1961-f090-46fc-b65b-0ca99c149c5d",
   "metadata": {},
   "source": [
    "#### Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deb58d62-ea49-408e-b2ed-44b780a7a2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185847"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(0.8 * len(data))\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce4f98e5-b785-42c8-99be-c71677092e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232309"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "#Check\n",
    "len(train_data) + len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b0747-8230-4c8c-b392-7f429df312b0",
   "metadata": {},
   "source": [
    "#### taille de bloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdd83a50-037a-475f-9cf0-8833e0601aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([73, 61, 58,  1, 69, 62, 60, 65])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[88294:88294 + block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99aba2e6-8d4b-4f93-aeee-c8e91f48ecfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([133750,   5867, 174518, 145328])\n",
      "inputs :\n",
      "tensor([[71, 68, 73, 61, 78, 11,  0,  0],\n",
      "        [72,  1, 55, 71, 58, 54, 64, 62],\n",
      "        [62, 67, 64, 65, 58, 57,  1, 59],\n",
      "        [62, 58, 57,  1, 73, 61, 58, 62]])\n",
      "targets :\n",
      "tensor([[68, 73, 61, 78, 11,  0,  0,  3],\n",
      "        [ 1, 55, 71, 58, 54, 64, 62, 67],\n",
      "        [67, 64, 65, 58, 57,  1, 59, 58],\n",
      "        [58, 57,  1, 73, 61, 58, 62, 71]])\n"
     ]
    }
   ],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "    \n",
    "x, y = get_batch('train')\n",
    "print('inputs :')\n",
    "print(x)\n",
    "print('targets :')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e966f262-6933-4998-918e-72dc51d14825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n4Kwfgswrj:J1RqM]e MS05BTVxdNa\\'oJpQv!BMjIn0\\'aqUJZ:P*S2]oHOP-V! j3S,(U8:E;7?01GHc1S&s2g8NE0T,g6LsL,Q]excYpmWs*mdg;)fg6OazT3)A:mXaxmEimEK(wB9ydCME0hh;A2dl-I\\n.[m:OXA.RAYAEz7e UhHnh0ah-exWcKK  pMAe1!B\"\\npShOY:U3EU49HK*7Db[Jsdbo8\\n2s\\nvo0 M Lt6\\ufeffwrId\\'\\ufeff3ZD\\'laNq[s&uyqsa4E*L5Y;XM\\ngb.l-\\ufeffv)5Is0_RffH:4g6e1O L_RAxth-CsU2.h b5Jw,gt&LuF9Z-pirIZr84OX(.4Uhk[wzTK6zTKzmWz;![\"S3ZJo5Bffo5Jpc\\nL_DK6B!1Wwz;km[lwB9;qOzilhmC[;fDG)faB\\'\\'YS]nfcaX5G)8:hk[s9vzD.u[QDe1WGIp*onr9Z:Jvz;\\'\\ufeffe1F\"FMH\\'n.;s]n lrQ_M0\\'Nt\\n37P!pi*GrB\\n hH3Vj71v\\''"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        if targets is None:\n",
    "            loss= None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(index)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "            \n",
    "        return index\n",
    "        \n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "\n",
    "generated_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "201cb059-d3dc-4ec8-9ac8-f0ff453ad895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82875ce6-e8e9-4ad2-a7cb-08d61b20d404",
   "metadata": {},
   "source": [
    "On va créer des blocs de taille `block_size` avec le jeu d'entrainement et la prédiction sera un bloc de même taille décalé d'un token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d94ec5b-76b5-4165-85d6-90f88d22423d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quand l'entrée est tensor([80]) l'objectif est tensor(1)\n",
      "Quand l'entrée est tensor([80,  1]) l'objectif est tensor(1)\n",
      "Quand l'entrée est tensor([80,  1,  1]) l'objectif est tensor(28)\n",
      "Quand l'entrée est tensor([80,  1,  1, 28]) l'objectif est tensor(39)\n",
      "Quand l'entrée est tensor([80,  1,  1, 28, 39]) l'objectif est tensor(42)\n",
      "Quand l'entrée est tensor([80,  1,  1, 28, 39, 42]) l'objectif est tensor(39)\n",
      "Quand l'entrée est tensor([80,  1,  1, 28, 39, 42, 39]) l'objectif est tensor(44)\n",
      "Quand l'entrée est tensor([80,  1,  1, 28, 39, 42, 39, 44]) l'objectif est tensor(32)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(\"Quand l'entrée est\", context, \"l'objectif est\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78ab067f-e411-4d2f-ad88-44d01d9ae5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a1dfb-5f4e-411e-8973-14a85a716c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300802d-93b5-413f-abaa-34c06c0c45f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
